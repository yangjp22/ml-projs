{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T19:13:17.132099Z",
     "start_time": "2019-07-01T19:13:16.263363Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the new dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T19:13:18.988452Z",
     "start_time": "2019-07-01T19:13:18.666316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "18846\n",
      "18846\n"
     ]
    }
   ],
   "source": [
    "# loading the new dataset\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "print(news.target_names)\n",
    "print(len(news.data))\n",
    "print(len(news.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T19:13:21.119736Z",
     "start_time": "2019-07-01T19:13:21.103781Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the new data into the training set and testing set\n",
    "x_train,x_test,y_train,y_test = train_test_split(news.data,news.target, random_state = 1234)\n",
    "# train = fetch_20newsgroups(subset='train')\n",
    "# x_train = train.data\n",
    "# y_train = train.target\n",
    "# test = fetch_20newsgroups(subset='test')\n",
    "# x_test = test.data\n",
    "# y_test = test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T19:13:31.090964Z",
     "start_time": "2019-07-01T19:13:25.066772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "# create countVectorizer instance and transform the dataset\n",
    "cv = CountVectorizer()\n",
    "cv_data = cv.fit_transform(x_train)\n",
    "\n",
    "# create a classification instance and use the cross_valuadation\n",
    "mul_nb = MultinomialNB()\n",
    "\n",
    "scores = model_selection.cross_val_score(mul_nb, cv_data, y_train, cv = 5, scoring = 'accuracy')\n",
    "print(\"Accuracy: %0.3f\" % (scores.mean())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T19:13:42.188301Z",
     "start_time": "2019-07-01T19:13:35.957184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.841\n"
     ]
    }
   ],
   "source": [
    "# create TfidfVectorizer instance and transform the dataset\n",
    "tdf_vectorizer = TfidfVectorizer()\n",
    "tdf_data = tdf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "scores = model_selection.cross_val_score(mul_nb, tdf_data, y_train, cv = 5, scoring = 'accuracy')\n",
    "print(\"Accuracy: %0.3f\" % (scores.mean())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude the influence of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T19:13:54.347342Z",
     "start_time": "2019-07-01T19:13:46.694837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\language\\python\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['camq', 're'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.910\n",
      "Testing result: 0.912\n"
     ]
    }
   ],
   "source": [
    "# get the stop words set from file\n",
    "def get_stop_words(filename):\n",
    "    stop_words = set()\n",
    "    with open(filename, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        stop_words.add(line.strip())\n",
    "    \n",
    "    return stop_words\n",
    "\n",
    "# load the stop words\n",
    "filename = './stopwords_en.txt'\n",
    "stop_words = get_stop_words(filename)\n",
    "\n",
    "# create the td_idf instance and insert the stop_words\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "tfidf_train = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# create a Multinomial Naive Bayes model\n",
    "mul_nb = MultinomialNB(alpha = 0.01)\n",
    "scores = model_selection.cross_val_score(mul_nb, tfidf_train, y_train, cv = 5, scoring='accuracy') \n",
    "print(\"Accuracy: %0.3f\" % (scores.mean())) \n",
    "\n",
    "mul_nb.fit(tfidf_train, y_train)\n",
    "\n",
    "print('Testing result: %0.3f' % (mul_nb.score(vectorizer.transform(x_test) , y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
